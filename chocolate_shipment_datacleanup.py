# -*- coding: utf-8 -*-
"""Chocolate-Shipment-DataCleanup.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1JzS7j7Wa4WEuL7_9p_3_cZSm4ASu8Ekf
"""

# Python Clean up:
import pandas as pd
from datetime import datetime

# Shipments Table Cleanup
shipments = pd.read_csv("Shipments.csv")

# Drop duplicates
shipments.drop_duplicates(subset="ShipmentID", inplace=True)

# Fill missing foreign keys with "Unknown"
shipments.fillna({"SPID": "Unknown", "PID": "Unknown", "GID": "Unknown"}, inplace=True)

# Convert Shipdate to datetime & remove future dates
shipments["Shipdate"] = pd.to_datetime(shipments["Shipdate"], errors="coerce")
shipments = shipments[shipments["Shipdate"] <= datetime.today()]

# Replace negative/NaN Amount with 0
shipments["Amount"] = shipments["Amount"].apply(lambda x: max(x, 0) if pd.notna(x) else 0)

# Remove outliers in Boxes (> 1000 considered invalid here)
shipments = shipments[shipments["Boxes"] <= 1000]

# Standardize order status
shipments["Order_Status"] = shipments["Order_Status"].str.title().fillna("Pending")

products = pd.read_csv("Products.csv")

# Drop duplicates
products.drop_duplicates(subset="PID", inplace=True)

# Standardize casing
products["Product"] = products["Product"].str.title()
products["Category"] = products["Category"].str.capitalize()

# Replace negative or missing costs with median
median_cost = products["Cost_per_box"].median()
products["Cost_per_box"] = products["Cost_per_box"].apply(
    lambda x: median_cost if pd.isna(x) or x < 0 else x
)

geo = pd.read_csv("Locations.csv")

# Drop duplicates
geo.drop_duplicates(subset="GID", inplace=True)

# Standardize casing
geo["Geo"] = geo["Geo"].str.title()
geo["Region"] = geo["Region"].str.upper()

sales = pd.read_csv("SalesPersons.csv")

# Drop duplicates
sales.drop_duplicates(subset="SPID", inplace=True)

# Standardize casing
sales["Sales_person"] = sales["Sales_person"].str.title()
sales["Team"] = sales["Team"].str.capitalize()

# Drop rows with missing/broken picture links
sales = sales[sales["Picture"].str.contains("http", na=False)]

calendar = pd.read_csv("Calendar.csv")

# Drop duplicates
calendar.drop_duplicates(subset="cal_date", inplace=True)

# Fix month and weekday ranges
calendar = calendar[(calendar["Month_num"] >= 1) & (calendar["Month_num"] <= 12)]
calendar = calendar[(calendar["weekday_num"] >= 1) & (calendar["weekday_num"] <= 7)]

# Keep only realistic years
calendar = calendar[(calendar["year"] >= 2000) & (calendar["year"] <= datetime.today().year)]